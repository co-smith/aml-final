import pandas as pd
import xarray as xr
import numpy as np
import glob
from sklearn.preprocessing import StandardScaler
import config
import os

print("--- Step 1: Preprocessing (Strict No-Leakage) ---")

# 1. Load NetCDF
file_list = glob.glob(config.DATA_DIR + "/*.nc")
if not file_list:
    print(f"ERROR: No .nc files found in {config.DATA_DIR}")
    exit()

ds = xr.open_mfdataset(file_list, combine='by_coords')
# Aggregate spatial dims
df = ds.mean(dim=['latitude', 'longitude']).to_dataframe()

# 2. Rename & Convert Units
df = df.rename(columns={'t2m': 'temp_2m', 'd2m': 'dewpoint_2m', 
                        'u10': 'wind_u_10m', 'v10': 'wind_v_10m', 'sp': 'surface_pressure'})
df['temp_2m'] -= 273.15
df['dewpoint_2m'] -= 273.15
df = df[['temp_2m', 'dewpoint_2m', 'wind_u_10m', 'wind_v_10m', 'surface_pressure']]

# 3. SPLIT FIRST (Crucial Step)
# We need to identify which rows belong to train to fit the scaler
train_mask = (df.index < config.VAL_START_DATE)

# 4. Fit Scaler ONLY on Training Data
scaler = StandardScaler()
scaler.fit(df.loc[train_mask]) 

# 5. Transform ALL Data using Training Statistics
# This ensures that if the test set is wildly different, the model sees that shift
df[df.columns] = scaler.transform(df)

# Save scaler params for unscaling later (derived from Train set only)
temp_mean = scaler.mean_[0]
temp_std = scaler.scale_[0]
with open(config.SCALER_PARAMS_PATH, "w") as f:
    f.write(f"{temp_mean},{temp_std}")
print(f"Saved scaler params (Train Set Only): Mean={temp_mean:.2f}, Std={temp_std:.2f}")

# 6. Generate Lags (Vectorized)
# Note: We create lags on the already scaled data. 
# This is fine, as linear operations preserve the scaling logic.
df_out = pd.DataFrame(index=df.index)

# We organize columns carefully for easier reshaping in dataset.py
# Format: [Feat1_t-5, Feat1_t-4 ... Feat1_t-0, Feat2_t-5 ...]
for col in df.columns:
    for i in range(config.SEQ_LEN):
        # lag_idx goes 5, 4, 3, 2, 1, 0
        lag_idx = (config.SEQ_LEN - 1) - i
        df_out[f'{col}_t-{lag_idx}'] = df[col].shift(lag_idx)

# 7. Generate Target: Delta T
# Target = Temp(t+1) - Temp(t-0)
# Note: These are differences in SCALED units (Sigma)
df_out['target_temp_t+1'] = df['temp_2m'].shift(-1) - df['temp_2m']

# Drop NaNs generated by shifting
df_out = df_out.dropna()

df_out.to_csv(config.PROCESSED_DATA_PATH)
print(f"Saved processed data to {config.PROCESSED_DATA_PATH}")